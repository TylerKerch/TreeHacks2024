{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a907a5-0af9-458f-b23b-fba9ed7d4adf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'inference_sdk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minference_sdk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InferenceHTTPClient\n\u001b[1;32m      3\u001b[0m CLIENT \u001b[38;5;241m=\u001b[39m InferenceHTTPClient(\n\u001b[1;32m      4\u001b[0m     api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://detect.roboflow.com\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJF6f1jrJCX2C3wG94y8b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'inference_sdk'"
     ]
    }
   ],
   "source": [
    "from inference_sdk import InferenceHTTPClient\n",
    "\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"JF6f1jrJCX2C3wG94y8b\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c655ed2d-51c5-4fd8-b2df-2f9abfbd8ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "result = CLIENT.infer('image.png', model_id=\"ui-screenshots/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38e0808-b276-4dc2-bccd-bbc1a1fe4a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel/.pyenv/versions/3.10.9/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading config.json: 100%|██████████| 4.19k/4.19k [00:00<00:00, 4.66MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 605M/605M [00:14<00:00, 40.6MB/s] \n",
      "2024-02-18 00:57:16.952232: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Downloading (…)rocessor_config.json: 100%|██████████| 316/316 [00:00<00:00, 866kB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 568/568 [00:00<00:00, 2.55MB/s]\n",
      "Downloading vocab.json: 100%|██████████| 862k/862k [00:00<00:00, 4.52MB/s]\n",
      "Downloading merges.txt: 100%|██████████| 525k/525k [00:00<00:00, 2.88MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 2.22M/2.22M [00:00<00:00, 8.85MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 389/389 [00:00<00:00, 1.77MB/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed2b9c4d-1ea2-4253-9333-ea9a7b206238",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar detection ID to the text query is: 75 with score 0.2573275864124298\n",
      "The most similar detection ID to the text query is: 151 with score 0.25092074275016785\n",
      "The most similar detection ID to the text query is: 127 with score 0.24906080961227417\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "\n",
    "# Initialize CLIP\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "from datetime import datetime\n",
    "# Load the image\n",
    "image_path = 'image'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Text query\n",
    "text_query = \"Go to home page\"\n",
    "text_input = processor(text=text_query, return_tensors=\"pt\", padding=True)\n",
    "text_features = model.get_text_features(**text_input)\n",
    "\n",
    "# Process sub-images in batches\n",
    "batch_size = 32  # Choose a batch size that fits your GPU memory\n",
    "sub_image_batches = []\n",
    "batch_predictions = []\n",
    "\n",
    "for detection_id, prediction in enumerate(result['predictions']):\n",
    "    x, y, width, height = prediction['x'], prediction['y'], prediction['width'], prediction['height']\n",
    "    sub_image = image.crop((x-width/2, y-height/2, x + width/2, y + height/2))\n",
    "    sub_image_batches.append(sub_image)\n",
    "    prediction['detection_id'] = detection_id\n",
    "    batch_predictions.append(prediction)\n",
    "\n",
    "    # When we reach the batch size, or at the end, process the batch\n",
    "    if len(sub_image_batches) == batch_size or detection_id == len(result['predictions']) - 1:\n",
    "        sub_image_inputs = processor(images=sub_image_batches, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        # Generate embeddings for the batch\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(**sub_image_inputs)\n",
    "\n",
    "        # Calculate cosine similarity for the batch\n",
    "        similarities = torch.nn.functional.cosine_similarity(image_features, text_features)\n",
    "\n",
    "        # Store similarities with detection_id for the batch\n",
    "        for prediction, similarity in zip(batch_predictions, similarities):\n",
    "            prediction['similarity'] = similarity.item()\n",
    "\n",
    "        # Clear the batch lists\n",
    "        sub_image_batches = []\n",
    "        batch_predictions = []\n",
    "\n",
    "# Find the prediction with the highest similarity\n",
    "# n = 3  # For example, to keep the top 3\n",
    "\n",
    "# Sort the predictions by similarity in descending order\n",
    "sorted_predictions = sorted(result['predictions'], key=lambda x: x['similarity'], reverse=True)\n",
    "text_query = \"Go to home page\"\n",
    "text_input = processor(text=text_query, return_tensors=\"pt\", padding=True)\n",
    "text_features = model.get_text_features(**text_input)\n",
    "\n",
    "# Process sub-images in batches\n",
    "batch_size = 32  # Choose a batch size that fits your GPU memory\n",
    "sub_image_batches = []\n",
    "batch_predictions = []\n",
    "\n",
    "for detection_id, prediction in enumerate(result['predictions']):\n",
    "    x, y, width, height = prediction['x'], prediction['y'], prediction['width'], prediction['height']\n",
    "    sub_image = image.crop((x-width/2, y-height/2, x + width/2, y + height/2))\n",
    "    sub_image_batches.append(sub_image)\n",
    "    prediction['detection_id'] = detection_id\n",
    "    batch_predictions.append(prediction)\n",
    "\n",
    "    # When we reach the batch size, or at the end, process the batch\n",
    "    if len(sub_image_batches) == batch_size or detection_id == len(result['predictions']) - 1:\n",
    "        sub_image_inputs = processor(images=sub_image_batches, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        # Generate embeddings for the batch\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(**sub_image_inputs)\n",
    "\n",
    "        # Calculate cosine similarity for the batch\n",
    "        similarities = torch.nn.functional.cosine_similarity(image_features, text_features)\n",
    "\n",
    "        # Store similarities with detection_id for the batch\n",
    "        for prediction, similarity in zip(batch_predictions, similarities):\n",
    "            prediction['similarity'] = similarity.item()\n",
    "\n",
    "        # Clear the batch lists\n",
    "        sub_image_batches = []\n",
    "        batch_predictions = []\n",
    "\n",
    "# Find the prediction with the highest similarity\n",
    "# n = 3  # For example, to keep the top 3\n",
    "\n",
    "# Sort the predictions by similarity in descending order\n",
    "sorted_predictions = sorted(result['predictions'], key=lambda x: x['similarity'], reverse=True)\n",
    "text_query = \"Go to home page\"\n",
    "text_input = processor(text=text_query, return_tensors=\"pt\", padding=True)\n",
    "text_features = model.get_text_features(**text_input)\n",
    "\n",
    "# Process sub-images in batches\n",
    "batch_size = 32  # Choose a batch size that fits your GPU memory\n",
    "sub_image_batches = []\n",
    "batch_predictions = []\n",
    "\n",
    "for detection_id, prediction in enumerate(result['predictions']):\n",
    "    x, y, width, height = prediction['x'], prediction['y'], prediction['width'], prediction['height']\n",
    "    sub_image = image.crop((x-width/2, y-height/2, x + width/2, y + height/2))\n",
    "    sub_image_batches.append(sub_image)\n",
    "    prediction['detection_id'] = detection_id\n",
    "    batch_predictions.append(prediction)\n",
    "\n",
    "    # When we reach the batch size, or at the end, process the batch\n",
    "    if len(sub_image_batches) == batch_size or detection_id == len(result['predictions']) - 1:\n",
    "        sub_image_inputs = processor(images=sub_image_batches, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        # Generate embeddings for the batch\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(**sub_image_inputs)\n",
    "\n",
    "        # Calculate cosine similarity for the batch\n",
    "        similarities = torch.nn.functional.cosine_similarity(image_features, text_features)\n",
    "\n",
    "        # Store similarities with detection_id for the batch\n",
    "        for prediction, similarity in zip(batch_predictions, similarities):\n",
    "            prediction['similarity'] = similarity.item()\n",
    "\n",
    "        # Clear the batch lists\n",
    "        sub_image_batches = []\n",
    "        batch_predictions = []\n",
    "\n",
    "# Find the prediction with the highest similarity\n",
    "# n = 3  # For example, to keep the top 3\n",
    "\n",
    "# Sort the predictions by similarity in descending order\n",
    "sorted_predictions = sorted(result['predictions'], key=lambda x: x['similarity'], reverse=True)\n",
    "text_query = \"Go to home page\"\n",
    "text_input = processor(text=text_query, return_tensors=\"pt\", padding=True)\n",
    "text_features = model.get_text_features(**text_input)\n",
    "\n",
    "# Process sub-images in batches\n",
    "batch_size = 32  # Choose a batch size that fits your GPU memory\n",
    "sub_image_batches = []\n",
    "batch_predictions = []\n",
    "\n",
    "for detection_id, prediction in enumerate(result['predictions']):\n",
    "    x, y, width, height = prediction['x'], prediction['y'], prediction['width'], prediction['height']\n",
    "    sub_image = image.crop((x-width/2, y-height/2, x + width/2, y + height/2))\n",
    "    sub_image_batches.append(sub_image)\n",
    "    prediction['detection_id'] = detection_id\n",
    "    batch_predictions.append(prediction)\n",
    "\n",
    "    # When we reach the batch size, or at the end, process the batch\n",
    "    if len(sub_image_batches) == batch_size or detection_id == len(result['predictions']) - 1:\n",
    "        sub_image_inputs = processor(images=sub_image_batches, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        # Generate embeddings for the batch\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(**sub_image_inputs)\n",
    "\n",
    "        # Calculate cosine similarity for the batch\n",
    "        similarities = torch.nn.functional.cosine_similarity(image_features, text_features)\n",
    "\n",
    "        # Store similarities with detection_id for the batch\n",
    "        for prediction, similarity in zip(batch_predictions, similarities):\n",
    "            prediction['similarity'] = similarity.item()\n",
    "\n",
    "        # Clear the batch lists\n",
    "        sub_image_batches = []\n",
    "        batch_predictions = []\n",
    "\n",
    "# Find the prediction with the highest similarity\n",
    "# n = 3  # For example, to keep the top 3\n",
    "\n",
    "# Sort the predictions by similarity in descending order\n",
    "sorted_predictions = sorted(result['predictions'], key=lambda x: x['similarity'], reverse=True)\n",
    "# Select the top n predictions\n",
    "top_n_predictions = sorted_predictions[:n]\n",
    "for prediction in top_n_predictions:\n",
    "    # Extract and preprocess sub-image\n",
    "    x, y, width, height = prediction['x'], prediction['y'], prediction['width'], prediction['height']\n",
    "    detection_id = prediction['detection_id']\n",
    "    sub_image = image.crop((x-width/2, y-height/2, x + width/2, y + height/2))\n",
    "    sub_image_input = processor(images=sub_image, return_tensors=\"pt\", padding=True)\n",
    "    # box_color = random_color()  # Generate a random color for each box\n",
    "    print(f\"The most similar detection ID to the text query is: {detection_id} with score {prediction['similarity']}\")\n",
    "    # draw.rectangle([x-width/2, y-height/2, x + width/2, y + height/2], outline=box_color, width=12)\n",
    "\n",
    "    # Add text\n",
    "    # draw.text((x-width/2, y-height/2 - 20), f'{detection_id}', fill=box_color,font=font)\n",
    "\n",
    "# Save or display the image\n",
    "unique_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the image with the unique ID in the filename\n",
    "image_path_with_id = f'output_{unique_id}.png'\n",
    "image.save(image_path_with_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "398ff1e6-cecf-4888-83e1-e4b81deec404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 tensor([0.7679], grad_fn=<SumBackward1>)\n",
      "1 3 tensor([0.8515], grad_fn=<SumBackward1>)\n",
      "1 4 tensor([0.7696], grad_fn=<SumBackward1>)\n",
      "1 5 tensor([0.9964], grad_fn=<SumBackward1>)\n",
      "1 6 tensor([0.9334], grad_fn=<SumBackward1>)\n",
      "2 3 tensor([0.7896], grad_fn=<SumBackward1>)\n",
      "2 4 tensor([0.7208], grad_fn=<SumBackward1>)\n",
      "2 5 tensor([0.7709], grad_fn=<SumBackward1>)\n",
      "2 6 tensor([0.7291], grad_fn=<SumBackward1>)\n",
      "3 4 tensor([0.7696], grad_fn=<SumBackward1>)\n",
      "3 5 tensor([0.8604], grad_fn=<SumBackward1>)\n",
      "3 6 tensor([0.8617], grad_fn=<SumBackward1>)\n",
      "4 5 tensor([0.7672], grad_fn=<SumBackward1>)\n",
      "4 6 tensor([0.7830], grad_fn=<SumBackward1>)\n",
      "5 6 tensor([0.9365], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "for i in range(1,7):\n",
    "    image_path = f'image{i}.png'\n",
    "    image = Image.open(image_path)\n",
    "    image_input = processor(images=image, return_tensors=\"pt\", padding=True)\n",
    "    image_features = model.get_image_features(**image_input)\n",
    "    vectors.append(image_features)\n",
    "    # Calculate cosine similarity\n",
    "for i in range(len(vectors)):\n",
    "    for j in range(i+1, len(vectors)):\n",
    "        similarity = torch.nn.functional.cosine_similarity(vectors[i], vectors[j])\n",
    "        print(i+1,j+1,similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21edff5b-e14d-4dda-9f13-6accfed748fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 0.09412937900015095, 'image': {'width': 3456, 'height': 2234}, 'predictions': [{'x': 1601.4375, 'y': 712.125, 'width': 691.875, 'height': 391.5, 'confidence': 0.9837357997894287, 'class': 'image', 'class_id': 4, 'detection_id': '694d1c7d-7141-46d1-b435-73986e649d80'}, {'x': 3056.0625, 'y': 717.1875, 'width': 698.625, 'height': 394.875, 'confidence': 0.9824270009994507, 'class': 'image', 'class_id': 4, 'detection_id': '00a79da1-9133-4f43-b3bd-a57453893c52'}, {'x': 2333.8125, 'y': 1427.625, 'width': 698.625, 'height': 391.5, 'confidence': 0.981886088848114, 'class': 'image', 'class_id': 4, 'detection_id': '4dab34dc-cd52-4bc4-b785-ffe34b4d32a4'}, {'x': 1601.4375, 'y': 715.5, 'width': 691.875, 'height': 391.5, 'confidence': 0.9733547568321228, 'class': 'button', 'class_id': 0, 'detection_id': 'ed3639e8-bd8e-4146-a027-dc4a8c5a2f02'}, {'x': 2333.8125, 'y': 713.8125, 'width': 698.625, 'height': 394.875, 'confidence': 0.9678884148597717, 'class': 'image', 'class_id': 4, 'detection_id': 'cafb346a-472d-4490-a797-ac2a39705ae9'}, {'x': 875.8125, 'y': 1425.9375, 'width': 705.375, 'height': 394.875, 'confidence': 0.9639768600463867, 'class': 'button', 'class_id': 0, 'detection_id': '5e0d9352-83de-4eae-9e39-84004b4fd28f'}, {'x': 3067.875, 'y': 1427.625, 'width': 681.75, 'height': 398.25, 'confidence': 0.9636505842208862, 'class': 'image', 'class_id': 4, 'detection_id': '6597011f-218f-4631-bf58-24e8cfa03975'}, {'x': 1599.75, 'y': 1424.25, 'width': 695.25, 'height': 391.5, 'confidence': 0.9614121317863464, 'class': 'image', 'class_id': 4, 'detection_id': 'd52d42ff-9ff0-45ab-bfbe-5e341281bf96'}, {'x': 2332.125, 'y': 715.5, 'width': 695.25, 'height': 391.5, 'confidence': 0.9565297961235046, 'class': 'button', 'class_id': 0, 'detection_id': 'ff756567-d504-4760-8148-ee4b464c821e'}, {'x': 1569.375, 'y': 1738.125, 'width': 621.0, 'height': 81.0, 'confidence': 0.941063404083252, 'class': 'heading', 'class_id': 2, 'detection_id': 'ab02b826-237d-452c-9d93-d9ddd483f1a2'}, {'x': 877.5, 'y': 1425.9375, 'width': 702.0, 'height': 394.875, 'confidence': 0.9397662878036499, 'class': 'image', 'class_id': 4, 'detection_id': '5c42c518-0810-4979-93f0-ff2fe3733a04'}, {'x': 3061.125, 'y': 1425.9375, 'width': 688.5, 'height': 394.875, 'confidence': 0.9380359649658203, 'class': 'button', 'class_id': 0, 'detection_id': 'd84ba313-0cda-42e1-8618-42b1ff1a319b'}, {'x': 1726.3125, 'y': 2153.25, 'width': 448.875, 'height': 162.0, 'confidence': 0.9374227523803711, 'class': 'image', 'class_id': 4, 'detection_id': '3fa38d76-6179-48bc-ad9a-71770facd116'}, {'x': 904.5, 'y': 1689.1875, 'width': 567.0, 'height': 84.375, 'confidence': 0.9351955652236938, 'class': 'heading', 'class_id': 2, 'detection_id': '3fbcaa6e-e0da-4b10-863b-14699d61ba66'}, {'x': 1240.3125, 'y': 2153.25, 'width': 448.875, 'height': 162.0, 'confidence': 0.9323360919952393, 'class': 'image', 'class_id': 4, 'detection_id': '12e258c6-e1c6-4873-b440-f76c65a6b174'}, {'x': 2205.5625, 'y': 2153.25, 'width': 442.125, 'height': 162.0, 'confidence': 0.9275079965591431, 'class': 'image', 'class_id': 4, 'detection_id': 'f656fab3-cba6-4891-bd48-0c4e9cc72321'}, {'x': 1601.4375, 'y': 1427.625, 'width': 691.875, 'height': 391.5, 'confidence': 0.9240099191665649, 'class': 'button', 'class_id': 0, 'detection_id': '08ee1bbb-702d-4b29-9dc0-7a28bde2fa01'}, {'x': 3089.8125, 'y': 978.75, 'width': 570.375, 'height': 87.75, 'confidence': 0.9220266342163086, 'class': 'heading', 'class_id': 2, 'detection_id': '767780cd-915c-4fff-9901-08883ac97c0c'}, {'x': 2345.625, 'y': 1689.1875, 'width': 540.0, 'height': 84.375, 'confidence': 0.9120818972587585, 'class': 'heading', 'class_id': 2, 'detection_id': 'd03afea1-09d9-4066-bac7-6309ce1edab3'}, {'x': 2700.0, 'y': 2153.25, 'width': 445.5, 'height': 162.0, 'confidence': 0.910300612449646, 'class': 'button', 'class_id': 0, 'detection_id': '73c03afb-da8a-4418-afb7-97d3eb14ca1c'}, {'x': 892.6875, 'y': 1689.1875, 'width': 543.375, 'height': 84.375, 'confidence': 0.908252477645874, 'class': 'button', 'class_id': 0, 'detection_id': '51d08053-353b-4391-8622-aa268786e72b'}, {'x': 2694.9375, 'y': 2153.25, 'width': 448.875, 'height': 162.0, 'confidence': 0.8885529041290283, 'class': 'image', 'class_id': 4, 'detection_id': '3e448d76-05b8-4068-971c-e868f7930179'}, {'x': 216.0, 'y': 874.125, 'width': 148.5, 'height': 33.75, 'confidence': 0.8885434865951538, 'class': 'text', 'class_id': 7, 'detection_id': '97e3163c-c93b-4378-af47-8ecaf8555af9'}, {'x': 1626.75, 'y': 977.0625, 'width': 560.25, 'height': 84.375, 'confidence': 0.8847111463546753, 'class': 'heading', 'class_id': 2, 'detection_id': 'fc83989f-80dd-4fe5-8ef9-5e2478f18a96'}, {'x': 1243.6875, 'y': 2153.25, 'width': 448.875, 'height': 162.0, 'confidence': 0.8758593201637268, 'class': 'button', 'class_id': 0, 'detection_id': '9f42d67c-a5a0-4297-8066-1de750bc5608'}, {'x': 1245.375, 'y': 416.8125, 'width': 236.25, 'height': 64.125, 'confidence': 0.8745955228805542, 'class': 'button', 'class_id': 0, 'detection_id': '1d4c63d9-bba1-419e-a9d4-153254c6489f'}, {'x': 2202.1875, 'y': 2153.25, 'width': 448.875, 'height': 162.0, 'confidence': 0.8739175796508789, 'class': 'button', 'class_id': 0, 'detection_id': '8bf70e03-67bc-4230-ac19-7cf340c33008'}, {'x': 229.5, 'y': 421.875, 'width': 405.0, 'height': 74.25, 'confidence': 0.8718852400779724, 'class': 'button', 'class_id': 0, 'detection_id': '5df58def-67c5-4add-88ca-85aa2a96c86e'}, {'x': 754.3125, 'y': 2153.25, 'width': 448.875, 'height': 162.0, 'confidence': 0.8713889718055725, 'class': 'image', 'class_id': 4, 'detection_id': 'b69a1ddd-04d0-45e8-9d76-75b53ceb23d7'}, {'x': 561.9375, 'y': 1682.4375, 'width': 77.625, 'height': 70.875, 'confidence': 0.864702582359314, 'class': 'image', 'class_id': 4, 'detection_id': '137ffc23-afc4-427c-a312-ed20810a0ba2'}, {'x': 1290.9375, 'y': 970.3125, 'width': 77.625, 'height': 70.875, 'confidence': 0.8620078563690186, 'class': 'image', 'class_id': 4, 'detection_id': 'ee107943-b048-4730-bbf6-7b007686404e'}, {'x': 1724.625, 'y': 2153.25, 'width': 445.5, 'height': 162.0, 'confidence': 0.861014723777771, 'class': 'button', 'class_id': 0, 'detection_id': 'fa3dd988-a39c-469f-ab04-a65c2aa6b4e0'}, {'x': 3182.625, 'y': 2153.25, 'width': 445.5, 'height': 162.0, 'confidence': 0.856276273727417, 'class': 'image', 'class_id': 4, 'detection_id': 'c6e092e5-3b65-4cdd-a952-30c20c0a390d'}, {'x': 219.375, 'y': 1658.8125, 'width': 155.25, 'height': 37.125, 'confidence': 0.8559732437133789, 'class': 'text', 'class_id': 7, 'detection_id': 'fced851f-e874-4928-a055-873bde5cfadf'}, {'x': 3066.1875, 'y': 1690.875, 'width': 516.375, 'height': 87.75, 'confidence': 0.8545660972595215, 'class': 'heading', 'class_id': 2, 'detection_id': 'e67ca094-bfb6-42f0-af08-e2ffb404e19f'}, {'x': 190.6875, 'y': 793.125, 'width': 97.875, 'height': 33.75, 'confidence': 0.8544664978981018, 'class': 'text', 'class_id': 7, 'detection_id': '5a9b269f-975f-4408-897a-d24a9115e9c3'}, {'x': 877.5, 'y': 757.6875, 'width': 702.0, 'height': 300.375, 'confidence': 0.851860523223877, 'class': 'image', 'class_id': 4, 'detection_id': 'c0e1890e-e3f6-490b-8ed9-5e2cb07ee331'}, {'x': 3066.1875, 'y': 717.1875, 'width': 705.375, 'height': 388.125, 'confidence': 0.8510466814041138, 'class': 'button', 'class_id': 0, 'detection_id': 'ef336585-12e9-4a60-b6ff-1170349cb3d0'}, {'x': 831.9375, 'y': 1098.5625, 'width': 293.625, 'height': 37.125, 'confidence': 0.8472844362258911, 'class': 'text', 'class_id': 7, 'detection_id': '57f47fb9-2e95-4ea2-bcac-9a88891fdd63'}, {'x': 779.625, 'y': 1800.5625, 'width': 310.5, 'height': 37.125, 'confidence': 0.8445391058921814, 'class': 'text', 'class_id': 7, 'detection_id': '383c12dd-fec0-482b-a31f-4a507d531760'}, {'x': 3180.9375, 'y': 2153.25, 'width': 448.875, 'height': 162.0, 'confidence': 0.8438956141471863, 'class': 'button', 'class_id': 0, 'detection_id': '6540c3f4-96b8-429e-be9f-0f148eca611c'}, {'x': 1329.75, 'y': 1810.6875, 'width': 148.5, 'height': 37.125, 'confidence': 0.8434090614318848, 'class': 'text', 'class_id': 7, 'detection_id': 'dd63a17e-1ced-4270-ae7a-1814f8b6e2a0'}, {'x': 2951.4375, 'y': 1800.5625, 'width': 286.875, 'height': 43.875, 'confidence': 0.8430185317993164, 'class': 'text', 'class_id': 7, 'detection_id': 'e3f92583-ebfe-4be2-8559-92659b786dae'}, {'x': 221.0625, 'y': 953.4375, 'width': 158.625, 'height': 37.125, 'confidence': 0.8429133892059326, 'class': 'text', 'class_id': 7, 'detection_id': '204fbf9a-ee4b-4565-a4c8-46bfe24a51db'}, {'x': 187.3125, 'y': 1147.5, 'width': 91.125, 'height': 40.5, 'confidence': 0.8384079933166504, 'class': 'text', 'class_id': 7, 'detection_id': '76a61e0c-b1d1-4280-8008-41ade2e23864'}, {'x': 567.0, 'y': 416.8125, 'width': 87.75, 'height': 64.125, 'confidence': 0.8258258104324341, 'class': 'button', 'class_id': 0, 'detection_id': 'fc1b254e-537e-4b20-a2ab-7d09a2a0a5db'}, {'x': 1635.1875, 'y': 302.0625, 'width': 1056.375, 'height': 77.625, 'confidence': 0.8242567777633667, 'class': 'field', 'class_id': 1, 'detection_id': 'a7f5a57b-971b-4f2c-b925-59c22e071e35'}, {'x': 2745.5625, 'y': 1682.4375, 'width': 77.625, 'height': 70.875, 'confidence': 0.8204658031463623, 'class': 'image', 'class_id': 4, 'detection_id': 'd20dd0f2-c543-4cad-a7c4-7d1bf85ac486'}, {'x': 1500.1875, 'y': 1810.6875, 'width': 165.375, 'height': 37.125, 'confidence': 0.8188904523849487, 'class': 'text', 'class_id': 7, 'detection_id': '442fca76-d66e-4ac3-9c5a-ae9a2cc54960'}, {'x': 227.8125, 'y': 583.875, 'width': 172.125, 'height': 40.5, 'confidence': 0.8143129944801331, 'class': 'text', 'class_id': 7, 'detection_id': 'b02697dd-6234-4b0b-b0c1-188926a0739d'}, {'x': 860.625, 'y': 1026.0, 'width': 654.75, 'height': 81.0, 'confidence': 0.8119573593139648, 'class': 'heading', 'class_id': 2, 'detection_id': 'fb7f5564-3fbe-4aa8-8213-b3507c1a2918'}, {'x': 750.9375, 'y': 2153.25, 'width': 448.875, 'height': 162.0, 'confidence': 0.8104486465454102, 'class': 'button', 'class_id': 0, 'detection_id': '163dfe54-1db2-48f5-b6df-3e8ee815b78f'}, {'x': 227.8125, 'y': 1503.5625, 'width': 381.375, 'height': 77.625, 'confidence': 0.8072159290313721, 'class': 'button', 'class_id': 0, 'detection_id': '96a81602-1919-47c9-95b7-2bdeb734e2a8'}, {'x': 202.5, 'y': 1501.875, 'width': 121.5, 'height': 40.5, 'confidence': 0.807134211063385, 'class': 'text', 'class_id': 7, 'detection_id': '2595ebad-6ae1-4f66-bf0e-21590342f9ca'}, {'x': 248.0625, 'y': 2139.75, 'width': 219.375, 'height': 40.5, 'confidence': 0.7935850620269775, 'class': 'text', 'class_id': 7, 'detection_id': 'b0550cff-7c66-444e-bba8-8d22c05ba7db'}, {'x': 145.125, 'y': 1076.625, 'width': 195.75, 'height': 40.5, 'confidence': 0.7933788895606995, 'class': 'text', 'class_id': 7, 'detection_id': '71bfa282-f77b-475a-b78a-4e5a42bbedca'}, {'x': 599.0625, 'y': 1100.25, 'width': 151.875, 'height': 33.75, 'confidence': 0.7907602787017822, 'class': 'text', 'class_id': 7, 'detection_id': 'b2ce4a3f-9d50-4886-bcd4-23b5ec75738d'}, {'x': 2330.4375, 'y': 1429.3125, 'width': 698.625, 'height': 394.875, 'confidence': 0.7837532758712769, 'class': 'button', 'class_id': 0, 'detection_id': 'f757b748-f438-41d9-adc5-fd91ba37a9c9'}, {'x': 2235.9375, 'y': 1802.25, 'width': 320.625, 'height': 40.5, 'confidence': 0.7830982208251953, 'class': 'text', 'class_id': 7, 'detection_id': '566ba12b-9b82-46ad-a2aa-c21e180af174'}, {'x': 874.125, 'y': 416.8125, 'width': 182.25, 'height': 64.125, 'confidence': 0.7830644845962524, 'class': 'button', 'class_id': 0, 'detection_id': '5baba36f-1489-4fbb-9784-9bf7fe8dac42'}, {'x': 237.9375, 'y': 956.8125, 'width': 408.375, 'height': 91.125, 'confidence': 0.7812064290046692, 'class': 'button', 'class_id': 0, 'detection_id': '2a26bd96-1988-4ee4-b45f-1ba298a3beab'}, {'x': 199.125, 'y': 1422.5625, 'width': 108.0, 'height': 37.125, 'confidence': 0.7809371948242188, 'class': 'text', 'class_id': 7, 'detection_id': 'adb2ffb7-1c79-4a49-913e-0632357827f7'}, {'x': 253.125, 'y': 1226.8125, 'width': 216.0, 'height': 37.125, 'confidence': 0.7788740396499634, 'class': 'text', 'class_id': 7, 'detection_id': 'b2ab9328-c76e-402a-a25c-9de5fcae3d32'}, {'x': 2747.25, 'y': 970.3125, 'width': 74.25, 'height': 70.875, 'confidence': 0.7784053087234497, 'class': 'image', 'class_id': 4, 'detection_id': 'eaeec1bc-1ffa-48ea-9631-f3e87f05fff1'}, {'x': 99.5625, 'y': 1351.6875, 'width': 118.125, 'height': 43.875, 'confidence': 0.7750338315963745, 'class': 'text', 'class_id': 7, 'detection_id': '17c967d6-c512-47d7-84ea-aab463c178a4'}, {'x': 2971.6875, 'y': 1090.125, 'width': 327.375, 'height': 40.5, 'confidence': 0.7750054001808167, 'class': 'text', 'class_id': 7, 'detection_id': 'c7c19fb5-8416-40b1-bd9c-25c63100df12'}, {'x': 1581.1875, 'y': 1668.9375, 'width': 651.375, 'height': 43.875, 'confidence': 0.7743403911590576, 'class': 'heading', 'class_id': 2, 'detection_id': '2d63f8d8-c7a5-413f-8661-9235bb0f0491'}, {'x': 185.625, 'y': 1981.125, 'width': 94.5, 'height': 40.5, 'confidence': 0.7656816244125366, 'class': 'text', 'class_id': 7, 'detection_id': 'd4a15fb4-c348-4018-ba57-bc545455035d'}, {'x': 2203.875, 'y': 1004.0625, 'width': 256.5, 'height': 43.875, 'confidence': 0.764285683631897, 'class': 'button', 'class_id': 0, 'detection_id': '0abe934d-d891-4df9-a82f-363716389b0d'}, {'x': 2158.3125, 'y': 1047.9375, 'width': 158.625, 'height': 37.125, 'confidence': 0.7598806619644165, 'class': 'text', 'class_id': 7, 'detection_id': '781eb1c2-ca02-4470-8a8d-232b0484a867'}, {'x': 249.75, 'y': 2141.4375, 'width': 438.75, 'height': 77.625, 'confidence': 0.7587841749191284, 'class': 'button', 'class_id': 0, 'detection_id': 'e676de39-40f2-4402-b38a-677c5b2156bd'}, {'x': 696.9375, 'y': 416.8125, 'width': 124.875, 'height': 64.125, 'confidence': 0.7574971914291382, 'class': 'button', 'class_id': 0, 'detection_id': '2e27115e-3ff5-4f2b-8b23-7502eb826940'}, {'x': 197.4375, 'y': 2062.125, 'width': 118.125, 'height': 40.5, 'confidence': 0.7539681792259216, 'class': 'text', 'class_id': 7, 'detection_id': 'd234ee2e-b4e8-415f-84f2-68f1566978f3'}, {'x': 231.1875, 'y': 1581.1875, 'width': 381.375, 'height': 70.875, 'confidence': 0.7473236322402954, 'class': 'button', 'class_id': 0, 'detection_id': 'ba6254bb-0397-4e0b-bab1-d59241fa0d2f'}, {'x': 2023.3125, 'y': 972.0, 'width': 77.625, 'height': 74.25, 'confidence': 0.745039701461792, 'class': 'image', 'class_id': 4, 'detection_id': '7c8d54a6-cce9-4d95-92e7-859efc51a5bc'}, {'x': 182.25, 'y': 504.5625, 'width': 87.75, 'height': 37.125, 'confidence': 0.7405933737754822, 'class': 'text', 'class_id': 7, 'detection_id': 'bdf7228d-18a9-4568-8582-fe64a40fbaa6'}, {'x': 229.5, 'y': 789.75, 'width': 432.0, 'height': 81.0, 'confidence': 0.7378386855125427, 'class': 'button', 'class_id': 0, 'detection_id': 'd69fb292-0940-4940-80d9-b3c68bb8cc61'}, {'x': 1658.8125, 'y': 415.125, 'width': 327.375, 'height': 67.5, 'confidence': 0.7369766235351562, 'class': 'button', 'class_id': 0, 'detection_id': 'bf749dfb-312e-4bc1-8e54-a1259b6db1c5'}, {'x': 194.0625, 'y': 1822.5, 'width': 111.375, 'height': 40.5, 'confidence': 0.7364176511764526, 'class': 'text', 'class_id': 7, 'detection_id': 'bf07e806-c271-418f-aa84-0c4e2b0dbc95'}, {'x': 2357.4375, 'y': 1690.875, 'width': 563.625, 'height': 87.75, 'confidence': 0.7358413338661194, 'class': 'button', 'class_id': 0, 'detection_id': '3ecb8423-d39f-483f-8bf8-f63fafd3f2ea'}, {'x': 226.125, 'y': 1982.8125, 'width': 398.25, 'height': 77.625, 'confidence': 0.7356948852539062, 'class': 'button', 'class_id': 0, 'detection_id': 'f57b8b0e-4248-4881-aee8-e7391d234d36'}, {'x': 2629.125, 'y': 416.8125, 'width': 229.5, 'height': 64.125, 'confidence': 0.7324608564376831, 'class': 'button', 'class_id': 0, 'detection_id': '0985155c-e827-4560-bf4b-db9ed6d7b665'}, {'x': 241.3125, 'y': 2062.125, 'width': 415.125, 'height': 74.25, 'confidence': 0.7322999238967896, 'class': 'button', 'class_id': 0, 'detection_id': '9614cb12-ac29-4e3f-88dd-a8538dfcc7ad'}, {'x': 2872.125, 'y': 1049.625, 'width': 128.25, 'height': 40.5, 'confidence': 0.7308762669563293, 'class': 'button', 'class_id': 0, 'detection_id': 'cdfb081e-ed3c-4805-916a-62281e9409c4'}, {'x': 229.5, 'y': 872.4375, 'width': 425.25, 'height': 77.625, 'confidence': 0.7264816761016846, 'class': 'button', 'class_id': 0, 'detection_id': '95a72128-3809-4928-a1d5-fb77da6c000c'}, {'x': 3105.0, 'y': 980.4375, 'width': 587.25, 'height': 91.125, 'confidence': 0.72345370054245, 'class': 'button', 'class_id': 0, 'detection_id': 'eb5068f3-138c-44af-b102-96fced0f0b31'}, {'x': 2823.1875, 'y': 416.8125, 'width': 84.375, 'height': 64.125, 'confidence': 0.7209196090698242, 'class': 'button', 'class_id': 0, 'detection_id': 'af7449bc-4414-4c3b-982f-aabde9acb833'}, {'x': 1047.9375, 'y': 416.8125, 'width': 97.875, 'height': 64.125, 'confidence': 0.7190647125244141, 'class': 'button', 'class_id': 0, 'detection_id': '1cd2dabb-9646-4271-8921-a059bd2baf38'}, {'x': 1640.25, 'y': 1000.6875, 'width': 573.75, 'height': 131.625, 'confidence': 0.7183613777160645, 'class': 'button', 'class_id': 0, 'detection_id': '089b09e0-b782-4ecb-bb33-eda86ea8c73e'}, {'x': 2306.8125, 'y': 980.4375, 'width': 455.625, 'height': 91.125, 'confidence': 0.7115693092346191, 'class': 'heading', 'class_id': 2, 'detection_id': 'b941d7e2-9819-4080-9c8b-e0db43722f37'}, {'x': 1566.0, 'y': 1738.125, 'width': 614.25, 'height': 81.0, 'confidence': 0.7061116695404053, 'class': 'button', 'class_id': 0, 'detection_id': 'b6391a36-93bd-406b-8fd8-faee3cd3fbff'}, {'x': 222.75, 'y': 1662.1875, 'width': 391.5, 'height': 77.625, 'confidence': 0.7027519941329956, 'class': 'button', 'class_id': 0, 'detection_id': 'ee345c33-d06b-4f1e-960c-b51b74c122b8'}, {'x': 212.625, 'y': 1822.5, 'width': 378.0, 'height': 81.0, 'confidence': 0.7017104625701904, 'class': 'button', 'class_id': 0, 'detection_id': '70bcecc4-0572-4118-b331-cd689e28427a'}, {'x': 1918.6875, 'y': 416.8125, 'width': 131.625, 'height': 64.125, 'confidence': 0.7001813650131226, 'class': 'text', 'class_id': 7, 'detection_id': 'af31eb45-9216-457d-b213-f2b56e813514'}, {'x': 2205.5625, 'y': 1761.75, 'width': 253.125, 'height': 40.5, 'confidence': 0.6966953873634338, 'class': 'button', 'class_id': 0, 'detection_id': 'c51d6e11-8d6d-4bbe-9205-2e74ae8f333c'}, {'x': 2322.0, 'y': 1047.9375, 'width': 162.0, 'height': 37.125, 'confidence': 0.6966177821159363, 'class': 'text', 'class_id': 7, 'detection_id': '55c46e11-a196-4276-9cd7-b1e1d412e4fd'}, {'x': 217.6875, 'y': 1900.125, 'width': 367.875, 'height': 74.25, 'confidence': 0.6949823498725891, 'class': 'button', 'class_id': 0, 'detection_id': '2fd5ff77-61f2-467f-860a-410fe4121cdd'}, {'x': 1498.5, 'y': 1090.125, 'width': 297.0, 'height': 33.75, 'confidence': 0.6901962161064148, 'class': 'text', 'class_id': 7, 'detection_id': '8d0f37ff-9947-4930-88c1-00e8a83fe24d'}, {'x': 70.875, 'y': 791.4375, 'width': 54.0, 'height': 50.625, 'confidence': 0.6894485950469971, 'class': 'image', 'class_id': 4, 'detection_id': '697940f2-7807-4ae8-92e0-39b0b11479e8'}, {'x': 3251.8125, 'y': 416.8125, 'width': 145.125, 'height': 64.125, 'confidence': 0.6854874491691589, 'class': 'button', 'class_id': 0, 'detection_id': '10701617-62cc-4030-a745-d377fa82ffa8'}, {'x': 216.0, 'y': 1743.1875, 'width': 384.75, 'height': 70.875, 'confidence': 0.6789945363998413, 'class': 'button', 'class_id': 0, 'detection_id': 'd0a21778-11fb-45e4-b2af-32d038f4628d'}, {'x': 3086.4375, 'y': 416.8125, 'width': 104.625, 'height': 64.125, 'confidence': 0.6784016489982605, 'class': 'button', 'class_id': 0, 'detection_id': '7fe94707-9b7e-4b9f-9367-10da177205b6'}, {'x': 232.875, 'y': 1420.875, 'width': 418.5, 'height': 74.25, 'confidence': 0.6769970655441284, 'class': 'button', 'class_id': 0, 'detection_id': '270b22fc-4021-4137-bb95-bfac6d107b93'}, {'x': 2345.625, 'y': 415.125, 'width': 263.25, 'height': 67.5, 'confidence': 0.668377161026001, 'class': 'button', 'class_id': 0, 'detection_id': 'e946cabe-3430-4717-920e-018548ceb91e'}, {'x': 3363.1875, 'y': 303.75, 'width': 70.875, 'height': 60.75, 'confidence': 0.6606991291046143, 'class': 'image', 'class_id': 4, 'detection_id': 'db1e3c72-ddf1-4e10-959b-eb9015188e16'}, {'x': 1429.3125, 'y': 415.125, 'width': 70.875, 'height': 67.5, 'confidence': 0.6555593609809875, 'class': 'button', 'class_id': 0, 'detection_id': 'f7c5d63b-9d5e-47f5-abee-f63fbc504672'}, {'x': 1140.75, 'y': 113.0625, 'width': 276.75, 'height': 30.375, 'confidence': 0.6528161764144897, 'class': 'text', 'class_id': 7, 'detection_id': '1a11f842-abf0-4751-a6c7-b69366d9fd2a'}, {'x': 249.75, 'y': 2210.625, 'width': 432.0, 'height': 47.25, 'confidence': 0.652093231678009, 'class': 'button', 'class_id': 0, 'detection_id': '77fac1f6-cb8d-42c8-bc0e-e869116cd99c'}, {'x': 607.5, 'y': 113.0625, 'width': 141.75, 'height': 30.375, 'confidence': 0.6409804821014404, 'class': 'text', 'class_id': 7, 'detection_id': '2112a5cd-0ed3-46c3-9193-bff7fd154720'}, {'x': 2318.625, 'y': 977.0625, 'width': 479.25, 'height': 84.375, 'confidence': 0.637988805770874, 'class': 'button', 'class_id': 0, 'detection_id': '9b84a197-5000-4636-9900-3d06bad99543'}, {'x': 1147.5, 'y': 114.75, 'width': 445.5, 'height': 81.0, 'confidence': 0.6356141567230225, 'class': 'button', 'class_id': 0, 'detection_id': '643bf774-b504-4c14-809f-e33d0ad6daed'}, {'x': 3088.125, 'y': 1690.875, 'width': 567.0, 'height': 87.75, 'confidence': 0.6348758339881897, 'class': 'button', 'class_id': 0, 'detection_id': 'ddc039b2-5b6e-417a-b545-b81a11ee93e8'}, {'x': 2057.0625, 'y': 111.375, 'width': 280.125, 'height': 33.75, 'confidence': 0.6347967386245728, 'class': 'text', 'class_id': 7, 'detection_id': 'f0ea8a36-dcbc-4bd5-bce8-1d7feba0f5cf'}, {'x': 2097.5625, 'y': 416.8125, 'width': 151.875, 'height': 64.125, 'confidence': 0.6325634717941284, 'class': 'button', 'class_id': 0, 'detection_id': 'f4141cfb-804a-4f75-8053-42bbdb0758fd'}, {'x': 232.875, 'y': 1228.5, 'width': 405.0, 'height': 87.75, 'confidence': 0.620124340057373, 'class': 'button', 'class_id': 0, 'detection_id': '8f98f491-24cf-41e4-9163-5295495b830d'}, {'x': 237.9375, 'y': 113.0625, 'width': 293.625, 'height': 30.375, 'confidence': 0.620084822177887, 'class': 'text', 'class_id': 7, 'detection_id': '8ea44a44-938c-43b3-80dc-6ca1f613085b'}, {'x': 2951.4375, 'y': 416.8125, 'width': 84.375, 'height': 64.125, 'confidence': 0.6162035465240479, 'class': 'button', 'class_id': 0, 'detection_id': 'b49e2b50-1cfb-46fe-aacc-b9ef0bb274bc'}, {'x': 182.25, 'y': 1579.5, 'width': 87.75, 'height': 33.75, 'confidence': 0.6135780215263367, 'class': 'text', 'class_id': 7, 'detection_id': '504129bc-fd2d-4ad3-99c6-25ac4f99052c'}, {'x': 75.9375, 'y': 713.8125, 'width': 64.125, 'height': 37.125, 'confidence': 0.6116529107093811, 'class': 'text', 'class_id': 7, 'detection_id': '3c677499-9097-4110-8aec-888e4e54c293'}, {'x': 200.8125, 'y': 2217.375, 'width': 124.875, 'height': 33.75, 'confidence': 0.608025312423706, 'class': 'text', 'class_id': 7, 'detection_id': '5247d9ce-33e5-4be0-b9a4-5f5a6ad526eb'}, {'x': 72.5625, 'y': 872.4375, 'width': 50.625, 'height': 43.875, 'confidence': 0.6005377769470215, 'class': 'image', 'class_id': 4, 'detection_id': '3fc72bd8-3132-4617-a5c2-39d496ac80d6'}, {'x': 720.5625, 'y': 1761.75, 'width': 192.375, 'height': 40.5, 'confidence': 0.5953879952430725, 'class': 'button', 'class_id': 0, 'detection_id': 'a0de8140-17df-4de0-a456-c87c432cfe35'}, {'x': 239.625, 'y': 587.25, 'width': 425.25, 'height': 87.75, 'confidence': 0.5786909461021423, 'class': 'button', 'class_id': 0, 'detection_id': '8933dead-7828-48cc-95aa-052bbdb08552'}, {'x': 583.875, 'y': 116.4375, 'width': 229.5, 'height': 84.375, 'confidence': 0.5718107223510742, 'class': 'button', 'class_id': 0, 'detection_id': '17780b91-8705-43df-aec5-f0e8d7bae143'}, {'x': 168.75, 'y': 1739.8125, 'width': 60.75, 'height': 37.125, 'confidence': 0.5679129362106323, 'class': 'text', 'class_id': 7, 'detection_id': '4e4c4478-86c5-4608-bbe7-0469bb123f3e'}, {'x': 180.5625, 'y': 1901.8125, 'width': 84.375, 'height': 37.125, 'confidence': 0.550574541091919, 'class': 'text', 'class_id': 7, 'detection_id': '3d0214be-3c62-4c02-9118-6b0a5ddc0123'}, {'x': 654.75, 'y': 838.6875, 'width': 148.5, 'height': 57.375, 'confidence': 0.5449801683425903, 'class': 'button', 'class_id': 0, 'detection_id': '49112ed2-56c1-4c65-8b36-46ecbb36c426'}, {'x': 222.75, 'y': 114.75, 'width': 432.0, 'height': 81.0, 'confidence': 0.530836284160614, 'class': 'button', 'class_id': 0, 'detection_id': 'a9c2fcb2-c1ec-4991-97de-8ff9124439c2'}, {'x': 2939.625, 'y': 1761.75, 'width': 263.25, 'height': 40.5, 'confidence': 0.5291823744773865, 'class': 'button', 'class_id': 0, 'detection_id': '08124121-1e83-4f66-a67c-6f4b9da8a01c'}, {'x': 2529.5625, 'y': 116.4375, 'width': 455.625, 'height': 77.625, 'confidence': 0.5216321349143982, 'class': 'button', 'class_id': 0, 'detection_id': '373f2c5a-b458-4d4c-ae33-9421b0be30c9'}, {'x': 74.25, 'y': 1226.8125, 'width': 54.0, 'height': 50.625, 'confidence': 0.5196153521537781, 'class': 'image', 'class_id': 4, 'detection_id': '84aed04a-8e1e-41c4-90c6-b36568e8c2e8'}, {'x': 1527.1875, 'y': 113.0625, 'width': 131.625, 'height': 30.375, 'confidence': 0.5153283476829529, 'class': 'text', 'class_id': 7, 'detection_id': 'fad816e6-6736-4ccc-81e6-4335d336039c'}, {'x': 2229.1875, 'y': 305.4375, 'width': 124.875, 'height': 77.625, 'confidence': 0.5150260925292969, 'class': 'button', 'class_id': 0, 'detection_id': '91ca1c22-d61a-478f-9371-f24d8de294c6'}, {'x': 236.25, 'y': 1147.5, 'width': 418.5, 'height': 74.25, 'confidence': 0.5147659778594971, 'class': 'button', 'class_id': 0, 'detection_id': '522c104d-cd1b-4fad-a3db-3cd5232fe8ec'}, {'x': 2754.0, 'y': 307.125, 'width': 843.75, 'height': 81.0, 'confidence': 0.5055211782455444, 'class': 'field', 'class_id': 1, 'detection_id': '5b213f6b-4892-41c6-bd11-0f5d9fa71c5c'}, {'x': 399.9375, 'y': 199.125, 'width': 165.375, 'height': 33.75, 'confidence': 0.4992368221282959, 'class': 'text', 'class_id': 7, 'detection_id': 'e5224e83-6f7b-4fdd-bfed-0fca185d623d'}, {'x': 234.5625, 'y': 708.75, 'width': 435.375, 'height': 81.0, 'confidence': 0.49667829275131226, 'class': 'button', 'class_id': 0, 'detection_id': 'dfff1eb1-cfd1-4d0a-9f92-07644f098177'}, {'x': 75.9375, 'y': 955.125, 'width': 50.625, 'height': 40.5, 'confidence': 0.49084097146987915, 'class': 'image', 'class_id': 4, 'detection_id': '25470058-1750-4e1c-84a3-1ce2f60424ee'}, {'x': 2018.25, 'y': 1687.5, 'width': 74.25, 'height': 74.25, 'confidence': 0.4887795150279999, 'class': 'image', 'class_id': 4, 'detection_id': '54fad28b-0724-4dfd-ae08-001defac9e77'}, {'x': 70.875, 'y': 1979.4375, 'width': 54.0, 'height': 43.875, 'confidence': 0.48486265540122986, 'class': 'image', 'class_id': 4, 'detection_id': '964dc9d5-df1c-4db4-9cb9-ce99020ca5c0'}, {'x': 761.0625, 'y': 693.5625, 'width': 469.125, 'height': 178.875, 'confidence': 0.47859546542167664, 'class': 'button', 'class_id': 0, 'detection_id': 'b2bdf72c-11d9-415e-bf8a-74635cc5dc3c'}, {'x': 3322.6875, 'y': 199.125, 'width': 239.625, 'height': 74.25, 'confidence': 0.46201375126838684, 'class': 'button', 'class_id': 0, 'detection_id': 'd17b9214-1a88-41f1-b0a7-142500766eee'}, {'x': 737.4375, 'y': 958.5, 'width': 408.375, 'height': 40.5, 'confidence': 0.4592142105102539, 'class': 'heading', 'class_id': 2, 'detection_id': '621105bf-ba1d-483e-b253-fc592f2cee3a'}, {'x': 1243.6875, 'y': 415.125, 'width': 192.375, 'height': 33.75, 'confidence': 0.45737767219543457, 'class': 'text', 'class_id': 7, 'detection_id': '514eb796-fe83-4e2e-8b4b-b277153c3158'}, {'x': 661.5, 'y': 1981.125, 'width': 135.0, 'height': 47.25, 'confidence': 0.4450852572917938, 'class': 'text', 'class_id': 7, 'detection_id': 'efb97f63-fa83-4cd4-8833-f9f75cb51250'}, {'x': 70.875, 'y': 1658.8125, 'width': 54.0, 'height': 43.875, 'confidence': 0.4440385103225708, 'class': 'image', 'class_id': 4, 'detection_id': '7f133e00-fb1c-4e76-a3f2-afac46daf189'}, {'x': 72.5625, 'y': 1420.875, 'width': 43.875, 'height': 40.5, 'confidence': 0.44244688749313354, 'class': 'image', 'class_id': 4, 'detection_id': 'a7b5cb2d-ee62-4201-90d7-db8104a61eaa'}, {'x': 72.5625, 'y': 1500.1875, 'width': 50.625, 'height': 50.625, 'confidence': 0.44208788871765137, 'class': 'image', 'class_id': 4, 'detection_id': '7876cee6-ca45-4bde-af9d-db37a1c48347'}, {'x': 2640.9375, 'y': 1596.375, 'width': 57.375, 'height': 33.75, 'confidence': 0.4418458640575409, 'class': 'text', 'class_id': 7, 'detection_id': '64737dad-2c18-4411-9e90-b92664b93d70'}, {'x': 3371.625, 'y': 1982.8125, 'width': 60.75, 'height': 57.375, 'confidence': 0.43798828125, 'class': 'image', 'class_id': 4, 'detection_id': '1b20d93c-1994-4469-9f01-99cf893bdd2b'}, {'x': 2458.6875, 'y': 113.0625, 'width': 185.625, 'height': 30.375, 'confidence': 0.4338723123073578, 'class': 'text', 'class_id': 7, 'detection_id': 'fb08f8fe-7b1b-4619-ba66-cb6660d709f0'}, {'x': 183.9375, 'y': 423.5625, 'width': 84.375, 'height': 30.375, 'confidence': 0.4326918423175812, 'class': 'text', 'class_id': 7, 'detection_id': '2b2a7ded-3f21-4c9d-a321-aab1ab09afb7'}, {'x': 234.5625, 'y': 1348.3125, 'width': 421.875, 'height': 64.125, 'confidence': 0.4287879467010498, 'class': 'button', 'class_id': 0, 'detection_id': 'e0324465-18ae-40e8-a63b-ca013414d137'}, {'x': 872.4375, 'y': 413.4375, 'width': 145.125, 'height': 37.125, 'confidence': 0.42842185497283936, 'class': 'text', 'class_id': 7, 'detection_id': '251986c7-cc08-4b60-8788-4ae8cc9b6f8d'}, {'x': 644.625, 'y': 1981.125, 'width': 168.75, 'height': 54.0, 'confidence': 0.42057913541793823, 'class': 'image', 'class_id': 4, 'detection_id': 'd7fd0335-591f-4661-8e90-b0b93568fe83'}, {'x': 2095.875, 'y': 416.8125, 'width': 148.5, 'height': 64.125, 'confidence': 0.42016786336898804, 'class': 'text', 'class_id': 7, 'detection_id': '1f840fbd-499b-4f82-9524-9094341180ca'}, {'x': 3248.4375, 'y': 303.75, 'width': 50.625, 'height': 47.25, 'confidence': 0.4101322889328003, 'class': 'image', 'class_id': 4, 'detection_id': '96d5922e-6f09-4fe5-8184-87dab44cf932'}]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9efd1cbf-5b92-4874-a79b-58c8b0d8f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uagents import Agent, Context, Protocol\n",
    "from uagents import Model\n",
    "\n",
    "user = Agent(\n",
    "    name=\"ui_description_user\",\n",
    "    port=8000,\n",
    "    endpoint=[\"http://127.0.0.1:8000/ui_description\"],\n",
    ")\n",
    "\n",
    "rag_user = Protocol(\"UI Description User\")\n",
    "\n",
    "\n",
    "class Request(Model):\n",
    "    message: str\n",
    "\n",
    "    \n",
    "class Data(Model):\n",
    "    image_summary: str\n",
    "    confidence: float\n",
    "    explanation: str\n",
    "\n",
    "@rag_user.on_query(model=Data)\n",
    "async def on_query(ctx: Context, sender: str, data: Data):  \n",
    "    ctx.logger.info(f\"Asking RAG agent to answer {QUESTION} based on document located at {URL}, readin nested pages too: {DEEP_READ}\")\n",
    "    await ctx.send('agent1q0666s65z2anr8zyt47n6g9s28fx7usfchxwdvcqxex4kg74vk0zkhvdxuf', Request(message=\"hello there bob\"))\n",
    "    ctx.logger.info(f\"Message has been sent to Bob\")\n",
    "\n",
    "\n",
    "@rag_user.on_message(model=Data)\n",
    "async def handle_data(ctx: Context, sender: str, data: Data):\n",
    "    ctx.logger.info(f\"Got response from RAG agent: {data.message}\")\n",
    "\n",
    "user.include(rag_user)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaee5b6-3fbb-48f1-b3ef-c3b4f07d1f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
